name: Run Scraper

on:
  schedule:
    - cron: '*/30 13-23 * * 1-5'   # 09:00–23:30 ET
    - cron: '*/30 0-4  * * 2-6'    # 00:00–04:00 ET
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    permissions:
      contents: write          # allow push via GITHUB_TOKEN

    steps:
      # 1️⃣  Checkout main (code) – fetch full history so we can reach branch `state`
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0

      # 2️⃣  Pull .last_seen.txt from branch `state` if it exists
      - name: Retrieve last_seen from state branch
        run: |
          if git ls-remote --exit-code --heads origin state >/dev/null; then
            git fetch origin state:state
            git checkout state -- .last_seen.txt || true
          else
            echo "state branch does not exist yet"
          fi

      # 3️⃣  Set up Python
      - uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      # 4️⃣  Install dependencies
      - run: pip install -r requirements.txt

      # 5️⃣  Run scraper (calls your Cloud‑Function‑style handler once)
      - name: Run scraper
        run: |
          python - <<'PY'
          import main
          main.scrape_handler(None)
          PY

      # 6️⃣  Commit & push only if .last_seen.txt changed
      - name: Commit updated last_seen
        run: |
          if git diff --quiet .last_seen.txt; then
            echo "No change in last_seen – skipping commit."
            exit 0
          fi

          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # switch (or create) branch `state`
          git checkout -B state
          git add .last_seen.txt
          git commit -m "Update last_seen $(date -u '+%Y-%m-%dT%H:%M:%SZ')"
          # push and overwrite remote state (low‑risk with single short file)
          git push --force-with-lease origin state
